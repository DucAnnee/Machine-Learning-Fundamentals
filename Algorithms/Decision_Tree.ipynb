{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"iris.csv\")\n",
    "header = [\"sepal.length\", \"sepal.width\", \"petal.length\", \"petal.width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approaching the problem\n",
    "Decision Tree is almost identical to when we want to decide a thing. For example, if we want to go swimming, we might consider if it's raining or not, or is the pool indoor or outdoor, etc.. However, computer obviously can't think about the question to ask in order to decide the outcome.\n",
    "\n",
    "That's why we need a criterion to decide what is the best question to ask. GINI impurity score will be implemented here. This is called choosing the best split.\n",
    "\n",
    "Like most tree building algorithm, we can build the tree recursively and for the base case, there are many complicated arguments involved, such as max depth of a tree, the min number of sample in a leaf, etc.. But those won't be considered and we will build the tree until no more leaf can be created.\n",
    "\n",
    "First, let's implement Gini. Gini impurity can be calculated by summing pairwise products of these probabilities for each class label, according to Wiki:\n",
    "\n",
    "$$ 1 - \\sum^{N}_{i=1} p_i^2 $$\n",
    "\n",
    "where N is the class count in the dataset and $p_i$ is the probability of choosing an item with label $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_count(data):\n",
    "    label_count = {}\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for _, row in data.iterrows():\n",
    "            label = row[-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "    else:\n",
    "        for row in data:\n",
    "            label = row[-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Setosa': 50, 'Versicolor': 50, 'Virginica': 50}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data):\n",
    "    label_count_ = label_count(data)\n",
    "    gini = 1\n",
    "    for label in label_count_:\n",
    "        prob = label_count_[label] / len(data)\n",
    "        gini -= prob**2\n",
    "    return gini\n",
    "\n",
    "\n",
    "def info_gain(left, right, current_purity):\n",
    "    w = float(len(left)) / (len(left) + len(right))\n",
    "    return current_purity - w * gini(left) - (1 - w) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_mixing = [[\"True\"], [\"True\"]]\n",
    "# this will return 0\n",
    "gini(no_mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixing = [[\"True\"], [\"False\"]]\n",
    "# this will return 0.5\n",
    "gini(mixing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function\n",
    "We need a function that can find the best question. More specifically, we can find the Gini score for each predictor and select the one with lowest impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, predictor, target):\n",
    "        self.predictor = predictor\n",
    "        self.target = target\n",
    "\n",
    "    def match(self, row):\n",
    "        val = row[self.predictor]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.target\n",
    "        else:\n",
    "            return val == self.target\n",
    "\n",
    "    def __repr__(self):\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.target):\n",
    "            condition = \">=\"\n",
    "        return f\"Is {header[self.predictor]} {condition} {str(self.target)}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Is sepal.width >= 5?"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This question will ask if sepal.length (index 1) >= 5\n",
    "q = Question(1, 5)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal.length       4.6\n",
      "sepal.width        3.1\n",
      "petal.length       1.5\n",
      "petal.width        0.2\n",
      "variety         Setosa\n",
      "Name: 3, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data.iloc[3]\n",
    "print(example)\n",
    "q.match(example)\n",
    "# this will return False as sepal.length is 4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to define the function that can partition the result of a question into 2 category True and False. Also, we want to have a function that can choose the best split for our decision nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    for _, row in data.iterrows():\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sepal.length       5.8\n",
       " sepal.width        4.0\n",
       " petal.length       1.2\n",
       " petal.width        0.2\n",
       " variety         Setosa\n",
       " Name: 14, dtype: object,\n",
       " sepal.length       5.7\n",
       " sepal.width        4.4\n",
       " petal.length       1.5\n",
       " petal.width        0.4\n",
       " variety         Setosa\n",
       " Name: 15, dtype: object,\n",
       " sepal.length       5.2\n",
       " sepal.width        4.1\n",
       " petal.length       1.5\n",
       " petal.width        0.1\n",
       " variety         Setosa\n",
       " Name: 32, dtype: object,\n",
       " sepal.length       5.5\n",
       " sepal.width        4.2\n",
       " petal.length       1.4\n",
       " petal.width        0.2\n",
       " variety         Setosa\n",
       " Name: 33, dtype: object]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rows, false_rows = partition(data, Question(1, 4))\n",
    "true_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(data):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_impurity = gini(data)\n",
    "    n_features = len(data.columns) - 1\n",
    "\n",
    "    for col in range(n_features):\n",
    "        values = set(data.iloc[:, col])\n",
    "        for val in values:\n",
    "            question = Question(col, val)\n",
    "            true_rows, false_rows = partition(data, question)\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            gain = info_gain(true_rows, false_rows, current_impurity)\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes for the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, data):\n",
    "        self.label_count_ = label_count(data)\n",
    "\n",
    "    def print(self):\n",
    "        total = sum(self.label_count_.values()) * 1.0\n",
    "        for label in self.label_count_:\n",
    "            print(label, self.label_count_[\n",
    "                  label] / total * 100, \"%\", end=\" | \")\n",
    "        print()\n",
    "\n",
    "\n",
    "class DecisionNode:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a tree\n",
    "1. Iterate through the dataset and select the best split (having the lowest purity) to be the root.\n",
    "2. If the information gain is not 0, partition into 2 child nodes. Else that is a leaf node.\n",
    "3. Repeat the process above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data):\n",
    "    best_gain, best_question = best_split(data)\n",
    "    if best_gain == 0:\n",
    "        return Leaf(data)\n",
    "    true_rows, false_rows = partition(data, best_question)\n",
    "    true_branch = build_tree(pd.DataFrame(true_rows))\n",
    "    false_branch = build_tree(pd.DataFrame(false_rows))\n",
    "    return DecisionNode(best_question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing, end=\"\")\n",
    "        node.print()\n",
    "        return\n",
    "    print(spacing + str(node.question))\n",
    "    print(spacing + \"--> True:\")\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "    print(spacing + \"--> False:\")\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is petal.width >= 1.0?\n",
      "--> True:\n",
      "  Is petal.width >= 1.8?\n",
      "  --> True:\n",
      "    Is petal.length >= 4.9?\n",
      "    --> True:\n",
      "      Virginica 100.0 % | \n",
      "    --> False:\n",
      "      Is sepal.width >= 3.2?\n",
      "      --> True:\n",
      "        Versicolor 100.0 % | \n",
      "      --> False:\n",
      "        Virginica 100.0 % | \n",
      "  --> False:\n",
      "    Is petal.length >= 5.0?\n",
      "    --> True:\n",
      "      Is petal.width >= 1.6?\n",
      "      --> True:\n",
      "        Is petal.length >= 5.8?\n",
      "        --> True:\n",
      "          Virginica 100.0 % | \n",
      "        --> False:\n",
      "          Versicolor 100.0 % | \n",
      "      --> False:\n",
      "        Virginica 100.0 % | \n",
      "    --> False:\n",
      "      Is petal.width >= 1.7?\n",
      "      --> True:\n",
      "        Virginica 100.0 % | \n",
      "      --> False:\n",
      "        Versicolor 100.0 % | \n",
      "--> False:\n",
      "  Setosa 100.0 % | \n"
     ]
    }
   ],
   "source": [
    "print_tree(build_tree(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "Let’s Write a Decision Tree Classifier from Scratch - Machine Learning Recipes #8. Retrieved from https://www.youtube.com/watch?v=LDRbO9a6XPU\n",
    "\n",
    "Decision Tree learning Wikipedia. Retrieved from https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
