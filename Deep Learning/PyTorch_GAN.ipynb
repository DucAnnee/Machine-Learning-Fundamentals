{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(torch.utils.data.DataModule):\n",
    "    def __init__(self, data_dir=\".\", batch_size=BATCH_SIZE):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        )\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_full = MNIST(\n",
    "            root=\".\", train=True, transform=self.transform, download=True\n",
    "        )\n",
    "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(\n",
    "            self.train_full, [55000, 5000]\n",
    "        )\n",
    "        self.test_dataset = MNIST(\n",
    "            root=\".\", train=False, transform=self.transform, download=True\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7 * 7 * 64)\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2)\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2)\n",
    "        self.conv = nn.Conv2d(16, 1, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)\n",
    "\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(torchvision.Module):\n",
    "    def __init__(self, latent_dim, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lr = lr\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.generator = Generator(latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "        self.validation_z = torch.randn(6, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, opt_idx):\n",
    "        real_imgs, _ = batch\n",
    "        z = torch.randn(real_imgs[0], self.latent_dim)\n",
    "        z = z.type_as(real_imgs)\n",
    "\n",
    "        # train generator: max log(D(G(z)))\n",
    "        if opt_idx == 0:\n",
    "            fake_imgs = self.generator(z)\n",
    "            validity = self.discriminator(fake_imgs)\n",
    "            g_loss = self.adversarial_loss(validity, torch.ones_like(validity))\n",
    "            return g_loss\n",
    "\n",
    "        # train discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        if opt_idx == 1:\n",
    "            real_validity = self.discriminator(real_imgs)\n",
    "            d_real_loss = self.adversarial_loss(\n",
    "                real_validity, torch.ones_like(real_validity)\n",
    "            )\n",
    "\n",
    "            fake_imgs = self.generator(z)\n",
    "            fake_validity = self.discriminator(fake_imgs.detach())\n",
    "            d_fake_loss = self.adversarial_loss(\n",
    "                fake_validity, torch.zeros_like(fake_validity)\n",
    "            )\n",
    "\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            return d_loss\n",
    "\n",
    "        return None\n",
    "\n",
    "    def config_optimizers(self):\n",
    "        opt_g = optim.Adam(self.generator.parameters(), lr=self.lr)\n",
    "        opt_d = optim.Adam(self.discriminator.parameters(), lr=self.lr)\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def plot_img(self):\n",
    "        z = self.validation_z.type_as(self.generator.lin1.weight)\n",
    "        sample_imgs = self(z).cpu()\n",
    "\n",
    "        print(\"epoch\", self.current_epoch)\n",
    "        for i in range(sample_imgs.size(0)):\n",
    "            plt.subplot(2, 3, i + 1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(\n",
    "                sample_imgs.detach()[i, 0, :, :], cmap=\"gray\", interpolation=\"none\"\n",
    "            )\n",
    "            plt.title(\"Generated data\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.plot_img()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
